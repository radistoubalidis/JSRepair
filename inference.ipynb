{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Colab Initialization"
      ],
      "metadata": {
        "id": "N8dYaxHs-X6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "U0PWG20r-b-Y",
        "outputId": "f9858623-d9bd-4c7d-da5b-322ae212eceb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/radistoubalidis/JSRepair.git\n",
        "\n",
        "!python -m pip install lightning\n",
        "!pip install datasets\n",
        "!pip install python-dotenv\n",
        "!pip install rouge-score\n",
        "!pip install diff-match-patch\n",
        "!pip install gspread google-auth"
      ],
      "metadata": {
        "id": "m5oDIZ9o-dGj",
        "outputId": "5462b73e-e720-43a7-983f-fbdfdee65fa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'JSRepair'...\n",
            "remote: Enumerating objects: 573, done.\u001b[K\n",
            "remote: Counting objects: 100% (89/89), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 573 (delta 60), reused 45 (delta 23), pack-reused 484 (from 1)\u001b[K\n",
            "Receiving objects: 100% (573/573), 2.17 MiB | 24.92 MiB/s, done.\n",
            "Resolving deltas: 100% (392/392), done.\n",
            "Collecting lightning\n",
            "  Downloading lightning-2.5.0.post0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2024.10.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (24.2)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (2.5.1+cu121)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning)\n",
            "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.12.2)\n",
            "Collecting pytorch-lightning (from lightning)\n",
            "  Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.11.11)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<4.0,>=2.1.0->lightning) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics<3.0,>=0.7.0->lightning) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.10)\n",
            "Downloading lightning-2.5.0.post0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Downloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.0.post0-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch-lightning, lightning\n",
            "Successfully installed lightning-2.5.0.post0 lightning-utilities-0.11.9 pytorch-lightning-2.5.0.post0 torchmetrics-1.6.1\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (4.67.1)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=b80509b0ff98ed1e008b87dcb2788393934bc856df77f93e6b78310ef9819801\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n",
            "Collecting diff-match-patch\n",
            "  Downloading diff_match_patch-20241021-py3-none-any.whl.metadata (5.5 kB)\n",
            "Downloading diff_match_patch-20241021-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: diff-match-patch\n",
            "Successfully installed diff-match-patch-20241021\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.11/dist-packages (6.1.4)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.11/dist-packages (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from gspread) (1.2.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ./JSRepair"
      ],
      "metadata": {
        "id": "GCHeRQyX-f1w",
        "outputId": "645b2e34-1b60-43c6-bb0d-83ba6d6b2efd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/JSRepair\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsisSI5n-Uon"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Kdr8fyQc-Uoo"
      },
      "outputs": [],
      "source": [
        "from modules.models import CodeT5, CodeBertJS\n",
        "from transformers import RobertaTokenizer\n",
        "from difflib import unified_diff\n",
        "from difflib import SequenceMatcher\n",
        "import pandas as pd\n",
        "import torch\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njmmTVFn-Uoo"
      },
      "source": [
        "# Load Model and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BYS3D-Hn-Uop",
        "outputId": "3f22c084-0286-416a-eff1-7cf7d2a737f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paste model checkpoint path: /content/drive/MyDrive/Thesis/checkpoints/CodeT5_base_JS_5classes_512MaxL_v906-v1.ckpt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CodeT5(\n",
              "  (model): T5ForConditionalGeneration(\n",
              "    (shared): Embedding(32100, 768)\n",
              "    (encoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32100, 768)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 12)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-11): 11 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (decoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32100, 768)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 12)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-11): 11 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (lm_head): Linear(in_features=768, out_features=32100, bias=False)\n",
              "  )\n",
              "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (hidden_layer): Linear(in_features=768, out_features=384, bias=True)\n",
              "  (activation): ReLU()\n",
              "  (dropout): Dropout(p=0.45, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "CPKT_PATH = input('Paste model checkpoint path: ')\n",
        "if not os.path.exists(CPKT_PATH):\n",
        "    raise FileNotFoundError(CPKT_PATH)\n",
        "MODEL_NAME = CPKT_PATH.split('/')[-1].split('.')[0].split('_')[0]\n",
        "\n",
        "if 'CodeT5' in MODEL_NAME:\n",
        "    HF_DIR = 'Salesforce/codet5-base'\n",
        "    model = CodeT5.load_from_checkpoint(\n",
        "        CPKT_PATH,\n",
        "        num_classes=5,\n",
        "        model_dir=HF_DIR,\n",
        "        with_activation=True,\n",
        "        with_layer_norm=True\n",
        "    )\n",
        "else:\n",
        "    HF_DIR = 'microsoft/codebert-base-mlm'\n",
        "    model = CodeBertJS.load_from_checkpoint(\n",
        "        CPKT_PATH,\n",
        "        num_classes=5,\n",
        "        model_dir=HF_DIR,\n",
        "        with_activation=True,\n",
        "        with_layer_norm=True\n",
        "    )\n",
        "\n",
        "model.eval()\n",
        "model.to('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p89Ag7HC-Uop"
      },
      "source": [
        "# Run inference on buggy code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "p0LIYdDp-Uop",
        "outputId": "0e40dfe4-3599-4112-d86e-b79f225b3778",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Select a bug type to run inference on (functionality network-security ui-ux compatibility-performance general): general\n",
            "Bug type: general\n",
            "--------------------- Buggy Code ---------------------\n",
            "// Write a function to display the Fibonacci sequence using recursion\n",
            "function fibonacci(n) {\n",
            "  if (n <= 1) {\n",
            "    return n;\n",
            "  } else {\n",
            "    return fibonacci(n + 1) + fibonacci(n + 2);\n",
            "  }\n",
            "}\n",
            "-------------------- Correct Code --------------------\n",
            "// Write a function to display the Fibonacci sequence using recursion\n",
            "function fibonacci(n) {\n",
            "  if (n <= 1) {\n",
            "    return n;\n",
            "  } else {\n",
            "    return fibonacci(n - 1) + fibonacci(n - 2);\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import sqlite3\n",
        "from modules.filters import add_labels\n",
        "\n",
        "classLabels = {\n",
        "        \"functionality\" : 0.,\n",
        "        \"ui-ux\" : 0.,\n",
        "        \"compatibility-performance\" : 0.,\n",
        "        \"network-security\" : 0.,\n",
        "        \"general\": 0.\n",
        "    }\n",
        "\n",
        "all_bug_types = ['functionality', 'network-security', 'ui-ux', 'compatibility-performance', 'general']\n",
        "all_bug_types_str = \" \".join(all_bug_types)\n",
        "bug_type = input(f\"Select a bug type to run inference on ({all_bug_types_str}): \")\n",
        "if bug_type not in all_bug_types:\n",
        "    raise Exception('Invalid Bug Type Selected')\n",
        "\n",
        "\n",
        "DB_TABLE = 'inference_examples.json'\n",
        "df = pd.read_json(DB_TABLE)\n",
        "df['class_labels'] = df['bug_type'].apply(lambda bT: add_labels(bT.split(','), classLabels))\n",
        "sample = df[df['bug_type'].str.contains(bug_type)].sample(1).iloc[0].to_dict()\n",
        "buggy_code, correct_code, bug_type, labels = sample['buggy_code'], sample['correct_code'], sample['bug_type'], torch.tensor(sample['class_labels'])\n",
        "\n",
        "print(f\"Bug type: {bug_type}\")\n",
        "print('--------------------- Buggy Code ---------------------')\n",
        "print(buggy_code)\n",
        "print('-------------------- Correct Code --------------------')\n",
        "print(correct_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SgyEN9ta-Uop",
        "outputId": "cd4344eb-3fb1-4abc-85dc-bda64b7fc28d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['functionality', 'compatibility-performance']\n",
            "// Write a function to display the Fibonacci sequence using recursion\n",
            "function fibonacci(n) {\n",
            "  if (n <= 1) {\n",
            "    return f;\n",
            "  } else if\n",
            "    return fibonacci(n + 1) + fibonacci(n + 2);\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained(HF_DIR)\n",
        "encoded_buggy_code = tokenizer(buggy_code, padding=True, truncation=True, return_tensors='pt')\n",
        "encoded_correct_code = tokenizer(correct_code, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "if 'CodeT5' in MODEL_NAME:\n",
        "    batch = {\n",
        "        'input_ids': encoded_buggy_code['input_ids'],\n",
        "        'attention_mask': encoded_buggy_code['attention_mask'],\n",
        "        'labels': encoded_correct_code['input_ids'],\n",
        "        'class_labels': labels\n",
        "    }\n",
        "else:\n",
        "    batch = {\n",
        "        'input_ids': encoded_buggy_code['input_ids'],\n",
        "        'attention_mask': encoded_buggy_code['attention_mask'],\n",
        "        'gt_input_ids': encoded_correct_code['input_ids'],\n",
        "        'class_labels': labels\n",
        "    }\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    _, out, bug_class = model.forward(batch)\n",
        "    preds = torch.sigmoid(bug_class)\n",
        "    probs = (preds > 0.5).float().tolist()[0]\n",
        "    pred_classes = []\n",
        "    for i, p in enumerate(probs):\n",
        "        if p == 1:\n",
        "            pred_classes.append(model.classes[i])\n",
        "\n",
        "print(pred_classes)\n",
        "generated_code = model.decode_output(out)\n",
        "print(generated_code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DIBqYBd-Uoq"
      },
      "source": [
        "# Συγκρίσεις"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPMxJGXD-Uoq"
      },
      "source": [
        "#### Διαφορές : Κώδικας με σφάλματα - Διορθωμένος κώδικας (ground truth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "x00LYT1x-Uoq",
        "outputId": "7fcc6af8-8f34-4635-b899-da919d8eba30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- \n",
            "\n",
            "+++ \n",
            "\n",
            "@@ -3,6 +3,6 @@\n",
            "\n",
            "   if (n <= 1) {\n",
            "     return n;\n",
            "   } else {\n",
            "-    return fibonacci(n + 1) + fibonacci(n + 2);\n",
            "+    return fibonacci(n - 1) + fibonacci(n - 2);\n",
            "   }\n",
            " }\n"
          ]
        }
      ],
      "source": [
        "real_codeDiff = unified_diff(buggy_code.splitlines(), correct_code.splitlines())\n",
        "print(\"\\n\".join(real_codeDiff))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00TM0816-Uoq"
      },
      "source": [
        "#### Διαφορες : Κώδικας με σφάλματα - Κώδικας που παρήγαγε το μοντέλο"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "S-XG6eii-Uoq",
        "outputId": "f2b10eff-6042-4562-8520-4d4c642c12b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- \n",
            "\n",
            "+++ \n",
            "\n",
            "@@ -1,8 +0,0 @@\n",
            "\n",
            "-// Write a function to display the Fibonacci sequence using recursion\n",
            "-function fibonacci(n) {\n",
            "-  if (n <= 1) {\n",
            "-    return n;\n",
            "-  } else {\n",
            "-    return fibonacci(n + 1) + fibonacci(n + 2);\n",
            "-  }\n",
            "-}\n"
          ]
        }
      ],
      "source": [
        "model_codeDiff = unified_diff(buggy_code.splitlines(), generated_code.splitlines())\n",
        "print(\"\\n\".join(model_codeDiff))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLHjONUA-Uor"
      },
      "source": [
        "#### Διαφορές : Κώδικας που παρήγαγε το μοντέλο - Διορθωμένος κώδικας"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fhf7whbn-Uor",
        "outputId": "2ed91676-3f84-45f0-8d82-b9e7b5db93e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- \n",
            "\n",
            "+++ \n",
            "\n",
            "@@ -0,0 +1,8 @@\n",
            "\n",
            "+// Write a function to display the Fibonacci sequence using recursion\n",
            "+function fibonacci(n) {\n",
            "+  if (n <= 1) {\n",
            "+    return n;\n",
            "+  } else {\n",
            "+    return fibonacci(n - 1) + fibonacci(n - 2);\n",
            "+  }\n",
            "+}\n"
          ]
        }
      ],
      "source": [
        "codeDiff = unified_diff(generated_code.splitlines(), correct_code.splitlines())\n",
        "print(\"\\n\".join(codeDiff))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA58z4IA-Uor"
      },
      "source": [
        "### Σύγκριση χαρακτήρων:\n",
        "\n",
        "#### Σύγκριση χαρακτήρα προς χαρακτήρα μεταξύ του κώδικα με σφάλματα (ακολουθία εισόδου) με τον διορθωμένο κώδικα (ground truth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "GuBlAMma-Uor",
        "outputId": "29101f64-35cd-414d-8f5f-1b04dd30562d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace\n",
            "+\n",
            "\n",
            "replace\n",
            "+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sm = SequenceMatcher(None, buggy_code, correct_code)\n",
        "\n",
        "for opcode, i1,i2,j1,j2 in sm.get_opcodes():\n",
        "    if opcode != 'equal':\n",
        "        print(opcode)\n",
        "        if opcode == 'insert':\n",
        "            print(generated_code[j1:j2])\n",
        "        elif opcode == 'replace':\n",
        "            print(buggy_code[i1:i2])\n",
        "            print(generated_code[j1:j2])\n",
        "        elif opcode == 'delete':\n",
        "            print(buggy_code[i1:i2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_5qDTtT-Uor"
      },
      "source": [
        "### Σύκγριση Χαρακτήρων:\n",
        "\n",
        "#### Σύγκριση χαρακτήρα προς χαρακτήρα μεταξύ του κώδικα που παρήγαγε το μοντέλο με τον διορθωμένο κώδικα (ground truth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "mF_zGboo-Uor",
        "outputId": "da31827b-b9b4-497f-eec6-5d68f89cb2c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "delete\n",
            "// Write a function to display the Fibonacci sequence using recursion\n",
            "function fibonacci(n) {\n",
            "  if (n <= 1) {\n",
            "    return n;\n",
            "  } else {\n",
            "    return fibonacci(n + 1) + fibonacci(n + 2);\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "sm = SequenceMatcher(None, buggy_code, generated_code)\n",
        "\n",
        "for opcode, i1,i2,j1,j2 in sm.get_opcodes():\n",
        "    if opcode != 'equal':\n",
        "        print(opcode)\n",
        "        if opcode == 'insert':\n",
        "            print(generated_code[j1:j2])\n",
        "        elif opcode == 'replace':\n",
        "            print(buggy_code[i1:i2])\n",
        "            print(generated_code[j1:j2])\n",
        "        elif opcode == 'delete':\n",
        "            print(buggy_code[i1:i2])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}