{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colab Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pa7PA6UMH2pn",
    "outputId": "cf90110e-36c6-4548-e514-d627463b9aea"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "eOOMW_SjH4WG",
    "outputId": "93d2e433-369f-4422-924e-d3b70ab27287"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/radistoubalidis/JSRepair.git\n",
    "\n",
    "!pip install pytorch_lightning\n",
    "!python -m pip install lightning\n",
    "!pip install datasets\n",
    "!pip install python-dotenv\n",
    "!pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eOMP9ujKQr0H",
    "outputId": "1103161d-11e5-4299-953b-bb803853980b"
   },
   "outputs": [],
   "source": [
    "%cd ./JSRepair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mi-6we72Hti5",
    "outputId": "93acf221-20cf-4126-8a24-4ad691905596"
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    RobertaTokenizer,\n",
    ")\n",
    "from modules.models import CodeT5\n",
    "from modules.datasets import CodeT5Dataset\n",
    "from modules.TrainConfig import init_logger, init_checkpoint, Trainer\n",
    "from modules.filters import add_labels, bug_type_dist_query\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_lightning import Trainer as plTrainer\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9liNYnTHti6",
    "outputId": "3cc1b8e0-0c42-486c-cecc-33d83605694d"
   },
   "outputs": [],
   "source": [
    "HF_DIR = 'Salesforce/codet5-base'\n",
    "TOKENIZER_MAX_LENGTH = 512 #int(input('Tokenizer Max length: '))\n",
    "DB_PATH = 'commitpack-datasets.db' if os.path.exists('commitpack-datasets.db') else '/content/drive/MyDrive/Thesis/commitpack-datasets.db'\n",
    "DB_TABLE = 'commitpackft_classified_train'\n",
    "if not os.path.exists(DB_PATH):\n",
    "    raise RuntimeError('sqlite3 path doesnt exist.')\n",
    "VAL_SIZE = 0.3\n",
    "LOG_PATH = 'logs' if os.path.exists('logs') else '/content/drive/MyDrive/Thesis/logs'\n",
    "VERSION = int(input('Training version: '))\n",
    "LOAD_FROM_CPKT = input(\"Load from existing model (type cpkt path if true): \")\n",
    "DEBUG = True if int(input('Debug Run (1,0): ')) == 1 else False\n",
    "BATCH_SIZE = 8 if DEBUG is True else 32\n",
    "CPKT_PATH = 'checkpoints' if os.path.exists('checkpoints') else '/content/drive/MyDrive/Thesis/checkpoints'\n",
    "DROPOUT_RATE = 0.125 #float(input('Type dropout rate for classifier: '))\n",
    "WITH_MOBILE = False #True if int(input('Consider mobile class (1,0): ')) == 1 else False\n",
    "WITH_LAYER_NORM = True\n",
    "WITH_ACTIVATION = True\n",
    "\n",
    "if WITH_MOBILE:\n",
    "    classLabels = {\n",
    "        \"mobile\" : 0.,\n",
    "        \"functionality\" : 0.,\n",
    "        \"ui-ux\" : 0.,\n",
    "        \"compatibility-performance\" : 0.,\n",
    "        \"network-security\" : 0.,\n",
    "        \"general\": 0.\n",
    "    }\n",
    "else:\n",
    "    classLabels = {\n",
    "        \"functionality\" : 0.,\n",
    "        \"ui-ux\" : 0.,\n",
    "        \"compatibility-performance\" : 0.,\n",
    "        \"network-security\" : 0.,\n",
    "        \"general\": 0.\n",
    "    }\n",
    "\n",
    "num_classes = len(classLabels.keys())\n",
    "modelSize = HF_DIR.split('-')[-1]\n",
    "MODEL_DIR = f\"CodeT5_{modelSize}_JS_{num_classes}classes_{TOKENIZER_MAX_LENGTH}MaxL\"\n",
    "con = sqlite3.connect(DB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87tUL_bQHti7"
   },
   "source": [
    "## Create Classification Labels\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"mobile\" : 0,\n",
    "    \"functionality\" : 0,\n",
    "    \"ui-ux\" : 0,\n",
    "    \"compatibility-performance\" : 0,\n",
    "    \"network-security\" : 0,\n",
    "    \"general\": 0\n",
    "}\n",
    "\n",
    "Ένα δείγμα που κατηγοριοποιήθηκε ως σφάλμα λειτουργικότητας(functionality) και ui-ux θα έχει διάνυσμα ταξινόμησης ->\n",
    "[0,1,1,0,0,0]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6mRHGm6JHti8",
    "outputId": "8104dc01-adc2-488a-87fe-5b5bb84e751f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>commit</th>\n",
       "      <th>old_file</th>\n",
       "      <th>new_file</th>\n",
       "      <th>old_contents</th>\n",
       "      <th>new_contents</th>\n",
       "      <th>subject</th>\n",
       "      <th>message</th>\n",
       "      <th>lang</th>\n",
       "      <th>license</th>\n",
       "      <th>repos</th>\n",
       "      <th>processed_message</th>\n",
       "      <th>is_bug</th>\n",
       "      <th>bug_type</th>\n",
       "      <th>class_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>29792</td>\n",
       "      <td>09d77f68de6320ac509775b7604e247b721528b5</td>\n",
       "      <td>root/tasks/connect.js</td>\n",
       "      <td>root/tasks/connect.js</td>\n",
       "      <td>/*\\n\\nSets up a connect server to work from th...</td>\n",
       "      <td>/*\\n\\nSets up a connect server to work from th...</td>\n",
       "      <td>Fix a bug where query strings would 404</td>\n",
       "      <td>Fix a bug where query strings would 404\\n</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>mit</td>\n",
       "      <td>seattletimes/newsapp-template,seattletimes/new...</td>\n",
       "      <td>fix bug queri string would 404</td>\n",
       "      <td>1</td>\n",
       "      <td>network-security</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4447</th>\n",
       "      <td>42212</td>\n",
       "      <td>7cf0a253819661c84e593d4a8dade96d1f4f253c</td>\n",
       "      <td>ghost/admin/controllers/forgotten.js</td>\n",
       "      <td>ghost/admin/controllers/forgotten.js</td>\n",
       "      <td>/* jshint unused: false */\\r\\nimport ajax from...</td>\n",
       "      <td>/* jshint unused: false */\\r\\nimport ajax from...</td>\n",
       "      <td>Stop validation error notification stack</td>\n",
       "      <td>Stop validation error notification stack\\n\\ncl...</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>mit</td>\n",
       "      <td>TryGhost/Ghost,TryGhost/Ghost,TryGhost/Ghost</td>\n",
       "      <td>stop valid error notif stack close # 3383 call...</td>\n",
       "      <td>1</td>\n",
       "      <td>ui-ux,compatibility-performance</td>\n",
       "      <td>[0.0, 1.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>22687</td>\n",
       "      <td>28e8fcd5f08aca3bb0b3abb9663a241bfcf395ce</td>\n",
       "      <td>administrator/templates/hubbasicadmin/js/compo...</td>\n",
       "      <td>administrator/templates/hubbasicadmin/js/compo...</td>\n",
       "      <td>if (typeof(Joomla) == 'undefined')\\n{\\n\\tJooml...</td>\n",
       "      <td>if (typeof(Joomla) == 'undefined')\\n{\\n\\tJooml...</td>\n",
       "      <td>Fix for script that can cause infinite loops u...</td>\n",
       "      <td>[TPL_HUBBASICADMIN] Fix for script that can ca...</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>mit</td>\n",
       "      <td>anthonyfuentes/hubzero-cms,zooley/hubzero-cms,...</td>\n",
       "      <td>tplhubbasicadmin fix script caus infinit loop ...</td>\n",
       "      <td>1</td>\n",
       "      <td>compatibility-performance</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6839</th>\n",
       "      <td>20412</td>\n",
       "      <td>ef920cf60564622f99642092e67f82b5d24d0db2</td>\n",
       "      <td>src/map/entities/footstep.js</td>\n",
       "      <td>src/map/entities/footstep.js</td>\n",
       "      <td>var Footstep = Entity.extend({\\n    alpha: 0.5...</td>\n",
       "      <td>var Footstep = Entity.extend({\\n    alpha: 0.5...</td>\n",
       "      <td>Fix graphical issue where they \"flicker\" when ...</td>\n",
       "      <td>[Content] Footstep: Fix graphical issue where ...</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>mit</td>\n",
       "      <td>burningtomatoes/CabinInTheSnow</td>\n",
       "      <td>content footstep fix graphic issu flicker fade...</td>\n",
       "      <td>1</td>\n",
       "      <td>ui-ux</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9824</th>\n",
       "      <td>26661</td>\n",
       "      <td>85bd7255c3fc4b106f32d45b928c8abfb8fa7ea2</td>\n",
       "      <td>lib/cmd.js</td>\n",
       "      <td>lib/cmd.js</td>\n",
       "      <td>\"use strict\";\\n\\nconst commands = {\\n\\t\\n\\t/* ...</td>\n",
       "      <td>\"use strict\";\\n\\nconst {exec} = require(\"child...</td>\n",
       "      <td>Fix missing function reference in Make command</td>\n",
       "      <td>Fix missing function reference in Make command\\n</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>isc</td>\n",
       "      <td>Alhadis/Atom-PhoenixTheme</td>\n",
       "      <td>fix miss function refer make command</td>\n",
       "      <td>1</td>\n",
       "      <td>functionality</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                    commit  \\\n",
       "1736  29792  09d77f68de6320ac509775b7604e247b721528b5   \n",
       "4447  42212  7cf0a253819661c84e593d4a8dade96d1f4f253c   \n",
       "92    22687  28e8fcd5f08aca3bb0b3abb9663a241bfcf395ce   \n",
       "6839  20412  ef920cf60564622f99642092e67f82b5d24d0db2   \n",
       "9824  26661  85bd7255c3fc4b106f32d45b928c8abfb8fa7ea2   \n",
       "\n",
       "                                               old_file  \\\n",
       "1736                              root/tasks/connect.js   \n",
       "4447               ghost/admin/controllers/forgotten.js   \n",
       "92    administrator/templates/hubbasicadmin/js/compo...   \n",
       "6839                       src/map/entities/footstep.js   \n",
       "9824                                         lib/cmd.js   \n",
       "\n",
       "                                               new_file  \\\n",
       "1736                              root/tasks/connect.js   \n",
       "4447               ghost/admin/controllers/forgotten.js   \n",
       "92    administrator/templates/hubbasicadmin/js/compo...   \n",
       "6839                       src/map/entities/footstep.js   \n",
       "9824                                         lib/cmd.js   \n",
       "\n",
       "                                           old_contents  \\\n",
       "1736  /*\\n\\nSets up a connect server to work from th...   \n",
       "4447  /* jshint unused: false */\\r\\nimport ajax from...   \n",
       "92    if (typeof(Joomla) == 'undefined')\\n{\\n\\tJooml...   \n",
       "6839  var Footstep = Entity.extend({\\n    alpha: 0.5...   \n",
       "9824  \"use strict\";\\n\\nconst commands = {\\n\\t\\n\\t/* ...   \n",
       "\n",
       "                                           new_contents  \\\n",
       "1736  /*\\n\\nSets up a connect server to work from th...   \n",
       "4447  /* jshint unused: false */\\r\\nimport ajax from...   \n",
       "92    if (typeof(Joomla) == 'undefined')\\n{\\n\\tJooml...   \n",
       "6839  var Footstep = Entity.extend({\\n    alpha: 0.5...   \n",
       "9824  \"use strict\";\\n\\nconst {exec} = require(\"child...   \n",
       "\n",
       "                                                subject  \\\n",
       "1736            Fix a bug where query strings would 404   \n",
       "4447           Stop validation error notification stack   \n",
       "92    Fix for script that can cause infinite loops u...   \n",
       "6839  Fix graphical issue where they \"flicker\" when ...   \n",
       "9824     Fix missing function reference in Make command   \n",
       "\n",
       "                                                message        lang license  \\\n",
       "1736          Fix a bug where query strings would 404\\n  JavaScript     mit   \n",
       "4447  Stop validation error notification stack\\n\\ncl...  JavaScript     mit   \n",
       "92    [TPL_HUBBASICADMIN] Fix for script that can ca...  JavaScript     mit   \n",
       "6839  [Content] Footstep: Fix graphical issue where ...  JavaScript     mit   \n",
       "9824   Fix missing function reference in Make command\\n  JavaScript     isc   \n",
       "\n",
       "                                                  repos  \\\n",
       "1736  seattletimes/newsapp-template,seattletimes/new...   \n",
       "4447       TryGhost/Ghost,TryGhost/Ghost,TryGhost/Ghost   \n",
       "92    anthonyfuentes/hubzero-cms,zooley/hubzero-cms,...   \n",
       "6839                     burningtomatoes/CabinInTheSnow   \n",
       "9824                          Alhadis/Atom-PhoenixTheme   \n",
       "\n",
       "                                      processed_message  is_bug  \\\n",
       "1736                     fix bug queri string would 404       1   \n",
       "4447  stop valid error notif stack close # 3383 call...       1   \n",
       "92    tplhubbasicadmin fix script caus infinit loop ...       1   \n",
       "6839  content footstep fix graphic issu flicker fade...       1   \n",
       "9824               fix miss function refer make command       1   \n",
       "\n",
       "                             bug_type               class_labels  \n",
       "1736                 network-security  [0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "4447  ui-ux,compatibility-performance  [0.0, 1.0, 1.0, 0.0, 0.0]  \n",
       "92          compatibility-performance  [0.0, 0.0, 1.0, 0.0, 0.0]  \n",
       "6839                            ui-ux  [0.0, 1.0, 0.0, 0.0, 0.0]  \n",
       "9824                    functionality  [1.0, 0.0, 0.0, 0.0, 0.0]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_ds() -> pd.DataFrame:\n",
    "    query = f\"select * from {DB_TABLE}\"\n",
    "    ds_df = pd.read_sql_query(query, con)\n",
    "    return ds_df\n",
    "\n",
    "ds_df = load_ds()\n",
    "\n",
    "ds_df['class_labels'] = ds_df['bug_type'].apply(lambda bT: add_labels(bT.split(','), classLabels))\n",
    "if DEBUG:\n",
    "    ds_df = ds_df.sample(500)\n",
    "\n",
    "if not WITH_MOBILE:\n",
    "    ds_df = ds_df[ds_df['bug_type'] != 'mobile']\n",
    "\n",
    "ds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out outlier samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples after filtering: 489\n"
     ]
    }
   ],
   "source": [
    "def count_comment_lines(sample: str) -> int:\n",
    "    comment_blocks = []\n",
    "    start_index = -1\n",
    "    for i, line in enumerate(sample.splitlines()):\n",
    "        if line.strip().startswith('/*'):\n",
    "            start_index = i\n",
    "        elif line.strip().endswith('*/'):\n",
    "            comment_blocks.append([start_index, i])\n",
    "            start_index = -1\n",
    "\n",
    "    comment_lines_count = sum([c[1]-c[0] for c in comment_blocks])\n",
    "\n",
    "    for i, line in enumerate(sample.splitlines()):\n",
    "        if line.strip().startswith('//'):\n",
    "            comment_lines_count += 1\n",
    "    return comment_lines_count\n",
    "\n",
    "ds_df['old_contents_comment_lines_count'] = ds_df['old_contents'].apply(lambda sample: count_comment_lines(sample))\n",
    "ds_df['new_contents_comment_lines_count'] = ds_df['new_contents'].apply(lambda sample: count_comment_lines(sample))\n",
    "\n",
    "# Filter out samples where the sum of comment lines increased more than 3 lines\n",
    "# to prevent excessive masking \n",
    "ds_df = ds_df[abs(ds_df['old_contents_comment_lines_count'] - ds_df['new_contents_comment_lines_count']) <= 3]\n",
    "print(f\"Total training samples after filtering: {len(ds_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate Commit Message with the old contents \n",
    "- This way, the commit message is directly provided as additional context, and the models (T5, Bert) can process both the buggy code and the commit message in a unified manner.\n",
    "- This approach will allow the model to learn the relationship between the commit message and the changes made to the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30946/2843727388.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  old_codes['input_seq'] = old_codes['message'] + ' ' + tokenizer.sep_token + ' ' + old_codes['old_contents']\n",
      "/tmp/ipykernel_30946/2843727388.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_codes['output_seq'] = new_codes['message'] + '  ' + tokenizer.sep_token + ' ' + new_codes['new_contents']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(HF_DIR)\n",
    "\n",
    "\n",
    "old_codes = ds_df[['message', 'old_contents', 'class_labels']]\n",
    "old_codes['input_seq'] = old_codes['message'] + ' ' + tokenizer.sep_token + ' ' + old_codes['old_contents']\n",
    "new_codes = ds_df[['message', 'new_contents', 'class_labels']]\n",
    "new_codes['output_seq'] = new_codes['message'] + '  ' + tokenizer.sep_token + ' ' + new_codes['new_contents']\n",
    "\n",
    "TRAIN_old, VAL_old, TRAIN_new, VAL_new = train_test_split(old_codes, new_codes, test_size=VAL_SIZE, random_state=42)\n",
    "\n",
    "print(f\"Total training samples: {len(ds_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bY7b8IO-JG2A"
   },
   "source": [
    "## Types of Bugs distribution in samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "urdA7KyTHti7",
    "outputId": "3648d104-7a17-40e7-dc43-fe89765df04e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count(*)</th>\n",
       "      <th>bug_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2862</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3147</td>\n",
       "      <td>ui-ux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3159</td>\n",
       "      <td>network-security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4396</td>\n",
       "      <td>compatibility-performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4532</td>\n",
       "      <td>functionality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count(*)                   bug_type\n",
       "0      2862                    general\n",
       "1      3147                      ui-ux\n",
       "2      3159           network-security\n",
       "3      4396  compatibility-performance\n",
       "4      4532              functionality"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = bug_type_dist_query(WITH_MOBILE, table='commitpackft_classified_train')\n",
    "\n",
    "info_df = pd.read_sql_query(query, con)\n",
    "info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qzy9IQ79Hti8"
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Wwhjv1FHti8",
    "outputId": "a759e85a-8dd1-4294-cead-a3d1d6687b6b"
   },
   "outputs": [],
   "source": [
    "TRAIN_encodings = tokenizer(\n",
    "    TRAIN_old['input_seq'].tolist(),\n",
    "    max_length=TOKENIZER_MAX_LENGTH,\n",
    "    pad_to_max_length=True,\n",
    "    return_tensors='pt',\n",
    "    padding='max_length',\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "VAL_encodings = tokenizer(\n",
    "    VAL_old['input_seq'].tolist(),\n",
    "    max_length=TOKENIZER_MAX_LENGTH,\n",
    "    pad_to_max_length=True,\n",
    "    return_tensors='pt',\n",
    "    padding='max_length',\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "TRAIN_decodings = tokenizer(\n",
    "    TRAIN_new['output_seq'].tolist(),\n",
    "    max_length=TOKENIZER_MAX_LENGTH,\n",
    "    pad_to_max_length=True,\n",
    "    return_tensors='pt',\n",
    "    padding='max_length',\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "VAL_decodings = tokenizer(\n",
    "    VAL_new['output_seq'].tolist(),\n",
    "    max_length=TOKENIZER_MAX_LENGTH,\n",
    "    pad_to_max_length=True,\n",
    "    return_tensors='pt',\n",
    "    padding='max_length',\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnVOxTTIHti9"
   },
   "source": [
    "### Convert Class Labels into tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hRoNjm0bHti9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_classes = torch.tensor(TRAIN_old['class_labels'].tolist())\n",
    "VAL_classes = torch.tensor(VAL_old['class_labels'].tolist())\n",
    "TRAIN_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute class weights\n",
    "$pos\\ weight[i] = (Number\\ of\\ negative\\ samples\\ for\\ class\\ i) / (Number\\ of\\ positive\\ samples\\ for\\ class\\ i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = TRAIN_classes.size(0)\n",
    "num_classes = TRAIN_classes.size(1)\n",
    "\n",
    "pos_counts = torch.sum(TRAIN_classes, dim=0)\n",
    "neg_counts = num_samples - pos_counts\n",
    "class_weights = neg_counts / (pos_counts + 1e-6)\n",
    "class_weights = class_weights.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-sIbpTJjJ3rB"
   },
   "source": [
    "## Initialize Training Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7a7NjypmHti9",
    "outputId": "b0d23edf-a2db-40f0-c296-0a5bda5ec59d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    }
   ],
   "source": [
    "logger = init_logger(log_path=LOG_PATH, model_dir=MODEL_DIR, version=VERSION)\n",
    "checkpoint = init_checkpoint(cpkt_path=CPKT_PATH, model_dir=MODEL_DIR, version=VERSION)\n",
    "trainer = Trainer(checkpoint,logger,debug=DEBUG, num_epochs=5)\n",
    "\n",
    "if len(LOAD_FROM_CPKT) > 0 and  os.path.exists(LOAD_FROM_CPKT):\n",
    "    model = CodeT5.load_from_checkpoint(\n",
    "        LOAD_FROM_CPKT, \n",
    "        class_weights=class_weights, \n",
    "        num_classes=num_classes,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        with_layer_norm=WITH_LAYER_NORM,\n",
    "        with_activation=WITH_ACTIVATION\n",
    "    )\n",
    "else:\n",
    "    model = CodeT5(\n",
    "        class_weights=class_weights, \n",
    "        num_classes=num_classes, \n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        with_layer_norm=WITH_LAYER_NORM,\n",
    "        with_activation=WITH_ACTIVATION\n",
    "    )\n",
    "model.model.train()\n",
    "\n",
    "TRAIN_dataset = CodeT5Dataset(TRAIN_encodings, TRAIN_decodings, TRAIN_classes)\n",
    "VAL_dataset = CodeT5Dataset(VAL_encodings, VAL_decodings, VAL_classes)\n",
    "from transformers import default_data_collator\n",
    "dataloader = DataLoader(TRAIN_dataset, batch_size=BATCH_SIZE,num_workers=14, shuffle=True, collate_fn=default_data_collator)\n",
    "val_dataloader = DataLoader(VAL_dataset, batch_size=1, num_workers=14, collate_fn=default_data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mhQtadvkHti9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disras/miniconda3/envs/thesis/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/disras/projects/JSRepair/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type                       | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | model        | T5ForConditionalGeneration | 222 M  | train\n",
      "1 | layer_norm   | LayerNorm                  | 1.5 K  | train\n",
      "2 | hidden_layer | Linear                     | 295 K  | train\n",
      "3 | activation   | ReLU                       | 0      | train\n",
      "4 | dropout      | Dropout                    | 0      | train\n",
      "5 | classifier   | Linear                     | 3.8 K  | train\n",
      "--------------------------------------------------------------------\n",
      "223 M     Trainable params\n",
      "0         Non-trainable params\n",
      "223 M     Total params\n",
      "892.731   Total estimated model params size (MB)\n",
      "546       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8369ad6f89642109e34418cea2da0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disras/miniconda3/envs/thesis/lib/python3.8/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d469c7a62142c7a64e306327be1260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=dataloader,\n",
    "    val_dataloaders=val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Model Config to CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelConfigsCSV = f\"/content/drive/MyDrive/Thesis/model-configs.csv\"\n",
    "if os.path.exists(modelConfigsCSV):\n",
    "    modelConfig = {\n",
    "        'name': MODEL_DIR,\n",
    "        'tokenizer_max_length': TOKENIZER_MAX_LENGTH,\n",
    "        'num_classes': num_classes,\n",
    "        'dropout_rate': DROPOUT_RATE,\n",
    "        'with_activation': WITH_ACTIVATION,\n",
    "        'with_layer_norm': WITH_LAYER_NORM\n",
    "    }\n",
    "    modelConfig_df = pd.DataFrame([modelConfig])\n",
    "    modelConfig_df.to_csv(modelConfigsCSV, mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_sql_query('select * from commitpackft_classified_test', con)\n",
    "test_df['class_labels'] = ds_df['bug_type'].apply(lambda bT: add_labels(bT, classLabels))\n",
    "if WITH_MOBILE:\n",
    "    test_df = test_df[test_df['bug_type'] != 'mobile']\n",
    "\n",
    "test_df['input_seq'] = test_df['message'] + ' ' + tokenizer.sep_token + ' ' + test_df['old_contents']\n",
    "\n",
    "if DEBUG:\n",
    "    test_df = test_df.iloc[:10]\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bug Type Distribution in Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bug-type-dist-query_test.sql', 'r')as f:\n",
    "    distQuery = f.read()\n",
    "f.close()\n",
    "info_df = pd.read_sql_query(distQuery, con)\n",
    "info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_classes = torch.tensor(ds_df['class_labels'].tolist())\n",
    "num_samples = TEST_classes.size(0)\n",
    "num_classes = TEST_classes.size(1)\n",
    "\n",
    "pos_counts = torch.sum(TEST_classes, dim=0)\n",
    "neg_counts = num_samples - pos_counts\n",
    "class_weights = neg_counts / (pos_counts + 1e-6)\n",
    "class_weights = class_weights.numpy()\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_samples = model.tokenizer(\n",
    "    test_df['input_seq'].tolist(),\n",
    "    max_length=TOKENIZER_MAX_LENGTH,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_tensors='pt',\n",
    ")\n",
    "\n",
    "encoded_labels = model.tokenizer(\n",
    "    test_df['new_contents'].tolist(),\n",
    "    max_length=TOKENIZER_MAX_LENGTH,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_tensors='pt',\n",
    ")\n",
    "\n",
    "labels = torch.tensor(ds_df['class_labels'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS_PATH = 'metrics' if os.path.exists('metrics') else '/content/drive/MyDrive/Thesis/metrics'\n",
    "os.environ['METRICS_PATH'] = METRICS_PATH\n",
    "os.environ['VERSION'] = str(VERSION)\n",
    "MODEL_NAME = 'CodeT5'\n",
    "os.environ['MODEL_NAME'] = MODEL_NAME\n",
    "\n",
    "\n",
    "torch_ds = CodeT5Dataset(encodings=encoded_samples, decodings=encoded_labels, class_labels=labels)\n",
    "loader = DataLoader(torch_ds, batch_size=1, num_workers=14)\n",
    "\n",
    "trainer = plTrainer()\n",
    "trainer.test(model=model, dataloaders=loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Metrics\n",
    "\n",
    "**ROUGE (Recall-Oriented understudy for Gisting Evaluation**\n",
    "- A metric for evaluation text generation/sumamrization models.\n",
    "- It measures the overlap between machine generated text (prediction) and its human generated corresponding text (reference)\\ \n",
    "- [0,1] { close to 0: poor similarity, close to 1: better similarity}\n",
    "- n-gram: seq of n words\n",
    "\n",
    "Variations\n",
    "- ROUGE-N : μετράει το σύνολο της επικάλυψης *[πόσες φορές εμφανίζετε στο παραγώμενο κείμενο]* το n-gram μεταξύ των προβλέψεων και του πραγματικού κειμένου\n",
    "\n",
    "- ROUGE-N_recall : num n gram matches / num of n-gram in reference\n",
    "- ROUGE-N-precision : nummber of n-gram matches / number of n gram in prediction\n",
    "- ROUGE-L : Βασίζεται στο μάκρος του μεγαλύτερης κοινής υπό-ακολουθίας (Longest Common Sequence -LCS) . Υπολογίζει το μέτρο f-measure\n",
    "    - ROUGE-L_recall : LCS / num words in reference\n",
    "    - ROUGE-L_precision : LCS / num words in prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.metrics import CodeRouge\n",
    "import json\n",
    "\n",
    "rouge = CodeRouge(['rouge7','rouge8','rouge9','rougeL','rougeLsum'])\n",
    "\n",
    "rouge.compute(predictions=model.generated_codes, references=test_df['new_contents'].tolist())\n",
    "rouge.calc_averages()\n",
    "\n",
    "avgs_path = f\"{METRICS_PATH}/{MODEL_NAME}_v{VERSION}/rouge.json\"\n",
    "all_path = f\"{METRICS_PATH}/{MODEL_NAME}_v{VERSION}/avg_rouge.csv\"\n",
    "with open(avgs_path, 'a') as f:\n",
    "    json.dump(rouge.avgs, f, indent=4)\n",
    "\n",
    "all_scores = []\n",
    "for r in rouge.rouge_types:\n",
    "    all_scores += rouge.rouge_type_to_list(r)\n",
    "\n",
    "metrics_df = pd.DataFrame(all_scores)\n",
    "\n",
    "for m in ['precision','recall','fmeasure']:\n",
    "    metrics_df[m] = round(metrics_df[m], 3)\n",
    "metrics_df.to_csv(all_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_avgs = rouge.avgs\n",
    "\n",
    "comparison_model_path = input('Comparison model avg ROUGE-N metrics path: ')\n",
    "comparison_model = comparison_model_path.split('/')[-2]\n",
    "if not os.path.exists(comparison_model_path):\n",
    "    raise RuntimeError('Metrics path does not exist.')\n",
    "\n",
    "with open(comparison_model_path, 'r') as f:\n",
    "    codet5_avgs = json.load(f)\n",
    "\n",
    "\n",
    "plot_data = {\n",
    "    f\"{MODEL_NAME}_{VERSION}\": (round(codebert_avgs['avg_rouge7'].fmeasure, 5), round(codebert_avgs['avg_rouge8'].fmeasure, 5), round(codebert_avgs['avg_rouge9'].fmeasure, 5), round(codebert_avgs['avg_rougeL'].fmeasure, 5), round(codebert_avgs['avg_rougeLsum'].fmeasure, 5)),\n",
    "    comparison_model: (round(codet5_avgs['avg_rouge7'][2], 5), round(codet5_avgs['avg_rouge8'][2], 5), round(codet5_avgs['avg_rouge9'][2], 5), round(codet5_avgs['avg_rougeL'][2], 5), round(codet5_avgs['avg_rougeLsum'][2], 5)),\n",
    "}\n",
    "\n",
    "metric_types = ('Rouge-7', 'Rouge-8','Rouge-9', 'Rouge-L', 'Rouge-Lsum')\n",
    "x = np.arange(len(metric_types))\n",
    "width = 0.15\n",
    "multiplier = 0\n",
    "\n",
    "fix, ax = plt.subplots(layout='constrained')\n",
    "\n",
    "\n",
    "for model, values in plot_data.items():\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, values, width, label=model)\n",
    "    ax.bar_label(rects, padding=3)\n",
    "    multiplier += 1\n",
    "\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('F-Measure Model Comparison')\n",
    "ax.set_xticks(x + width, metric_types)\n",
    "ax.legend(loc='upper left', ncols=4)\n",
    "ax.set_ylim(0, 1.2)\n",
    "\n",
    "plt.savefig(f\"{METRICS_PATH}/{MODEL_NAME}_{VERSION}_vs_{comparison_model}.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "codebert_avgs = rouge.avgs  # Assuming rouge is a library/function that provides average scores\n",
    "\n",
    "comparison_model_path = input('Comparison model avg ROUGE-N metrics path: ')\n",
    "comparison_model = comparison_model = comparison_model_path.split('/')[-2]\n",
    "if not os.path.exists(comparison_model_path):\n",
    "    raise RuntimeError('Metrics path does not exist.')\n",
    "\n",
    "with open(comparison_model_path, 'r') as f:\n",
    "    codet5_avgs = json.load(f)\n",
    "\n",
    "# Define metric types (assuming same metrics for both models)\n",
    "metric_types = ('Rouge-7', 'Rouge-8', 'Rouge-9', 'Rouge-L', 'Rouge-Lsum')\n",
    "\n",
    "# Create a figure with 3 rows (subplots) and 1 column\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(20, 16))\n",
    "\n",
    "# Data dictionaries for each metric (assuming data structure from rouge)\n",
    "precision_data = {\n",
    "    f\"{MODEL_NAME}_{VERSION}\": (codebert_avgs['avg_rouge7'].precision, codebert_avgs['avg_rouge8'].precision, codebert_avgs['avg_rouge9'].precision, codebert_avgs['avg_rougeL'].precision, codebert_avgs['avg_rougeLsum'].precision),\n",
    "    comparison_model: (codet5_avgs['avg_rouge7'][0], codet5_avgs['avg_rouge8'][0], codet5_avgs['avg_rouge9'][0], codet5_avgs['avg_rougeL'][0], codet5_avgs['avg_rougeLsum'][0]),\n",
    "}\n",
    "recall_data = {\n",
    "    f\"{MODEL_NAME}_{VERSION}\": (codebert_avgs['avg_rouge7'].recall, codebert_avgs['avg_rouge8'].recall, codebert_avgs['avg_rouge9'].recall, codebert_avgs['avg_rougeL'].recall, codebert_avgs['avg_rougeLsum'].recall),\n",
    "    comparison_model: (codet5_avgs['avg_rouge7'][1], codet5_avgs['avg_rouge8'][1], codet5_avgs['avg_rouge9'][1], codet5_avgs['avg_rougeL'][1], codet5_avgs['avg_rougeLsum'][1]),\n",
    "}\n",
    "f1_data = {\n",
    "    f\"{MODEL_NAME}_{VERSION}\": (codebert_avgs['avg_rouge7'].fmeasure, codebert_avgs['avg_rouge8'].fmeasure, codebert_avgs['avg_rouge9'].fmeasure, codebert_avgs['avg_rougeL'].fmeasure, codebert_avgs['avg_rougeLsum'].fmeasure),\n",
    "    comparison_model: (round(codet5_avgs['avg_rouge7'][2], 5), round(codet5_avgs['avg_rouge8'][2], 5), round(codet5_avgs['avg_rouge9'][2], 5), round(codet5_avgs['avg_rougeL'][2], 5), round(codet5_avgs['avg_rougeLsum'][2], 5)),\n",
    "}\n",
    "\n",
    "\n",
    "# Plot Precision (ax1)\n",
    "for model, precision in precision_data.items():\n",
    "    ax1.plot(metric_types, precision, label=model, marker='s')  # 's' for square marker\n",
    "ax1.set_xlabel('ROUGE-N')\n",
    "ax1.set_ylabel('Precision')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot Recall (ax2)\n",
    "for model, recall in recall_data.items():\n",
    "    ax2.plot(metric_types, recall, label=model, marker='s')  # 'o' for circle marker\n",
    "ax2.set_xlabel('ROUGE-N')\n",
    "ax2.set_ylabel('Recall')\n",
    "ax2.grid(True)\n",
    "\n",
    "# Plot F1 Score (ax3)\n",
    "for model, f1 in f1_data.items():\n",
    "    ax3.plot(metric_types, f1, label=model, marker='s')\n",
    "ax3.set_xlabel('ROUGE-N')\n",
    "ax3.set_ylabel('F-measure')\n",
    "ax3.grid(True)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the entire figure as a single PNG\n",
    "plt.savefig(f\"{METRICS_PATH}/{MODEL_NAME}_{VERSION}_vs_{comparison_model}.png\", dpi=300, bbox_inches='tight')\n",
    "ax"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
